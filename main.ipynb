{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [00:56<00:00, 17.70it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 15.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"Stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_ts = load_time_series(\"series_train.parquet\")\n",
    "test_ts = load_time_series(\"series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "5       1.0\n",
       "       ... \n",
       "3953    0.0\n",
       "3954    1.0\n",
       "3955    1.0\n",
       "3957    1.0\n",
       "3958    0.0\n",
       "Name: sii, Length: 2736, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', \n",
    "          'FGC-Season', 'BIA-Season', 'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('object')\n",
    "    return df\n",
    "        \n",
    "train = update(train)\n",
    "test = update(test)\n",
    "train['sii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['sii'] == 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2736 entries, 0 to 3958\n",
      "Columns: 155 entries, Basic_Demos-Enroll_Season to Stat_95\n",
      "dtypes: float64(143), int64(2), object(10)\n",
      "memory usage: 3.3+ MB\n",
      "None\n",
      "\n",
      "Test Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Columns: 154 entries, Basic_Demos-Enroll_Season to Stat_95\n",
      "dtypes: float64(142), int64(2), object(10)\n",
      "memory usage: 24.2+ KB\n",
      "None\n",
      "\n",
      "Missing Values in Train Dataset:\n",
      "PAQ_A-PAQ_A_Total               2373\n",
      "Physical-Waist_Circumference    2253\n",
      "Fitness_Endurance-Time_Sec      2008\n",
      "Fitness_Endurance-Time_Mins     2008\n",
      "Fitness_Endurance-Max_Stage     2005\n",
      "FGC-FGC_GSD_Zone                1872\n",
      "FGC-FGC_GSND_Zone               1872\n",
      "FGC-FGC_GSD                     1865\n",
      "FGC-FGC_GSND                    1864\n",
      "Stat_43                         1740\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Test Dataset:\n",
      "PAQ_A-PAQ_A_Total    19\n",
      "Stat_19              18\n",
      "Stat_47              18\n",
      "Stat_41              18\n",
      "Stat_42              18\n",
      "Stat_43              18\n",
      "Stat_44              18\n",
      "Stat_45              18\n",
      "Stat_46              18\n",
      "Stat_48              18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 檢視 train 和 test 資料的基本資訊\n",
    "print(\"Train Dataset Info:\")\n",
    "print(train.info())\n",
    "print(\"\\nTest Dataset Info:\")\n",
    "print(test.info())\n",
    "\n",
    "# 顯示缺失值分布\n",
    "print(\"\\nMissing Values in Train Dataset:\")\n",
    "print(train.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\nMissing Values in Test Dataset:\")\n",
    "print(test.isnull().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值處理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 針對連續型的資料特徵 ➡️ 使用中位數填補\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Continuous numerical missing values filled with median.\n"
     ]
    }
   ],
   "source": [
    "num_imputer = SimpleImputer(strategy='median')\n",
    "numerical_features = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "missing_in_test = [col for col in numerical_features if col not in test.columns]\n",
    "for col in missing_in_test:\n",
    "    test[col] = np.nan\n",
    "\n",
    "train[numerical_features] = num_imputer.fit_transform(train[numerical_features])\n",
    "test[numerical_features] = num_imputer.transform(test[numerical_features])\n",
    "print(\"✅ Continuous numerical missing values filled with median.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 針對類別型的資料特徵 ➡️ 使用多數填補\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic_Demos-Enroll_Season     object\n",
      "Basic_Demos-Age              float64\n",
      "Basic_Demos-Sex              float64\n",
      "CGAS-Season                   object\n",
      "CGAS-CGAS_Score              float64\n",
      "                              ...   \n",
      "Stat_91                      float64\n",
      "Stat_92                      float64\n",
      "Stat_93                      float64\n",
      "Stat_94                      float64\n",
      "Stat_95                      float64\n",
      "Length: 155, dtype: object\n",
      "Index(['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season',\n",
      "       'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', 'PAQ_A-Season',\n",
      "       'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season'],\n",
      "      dtype='object')\n",
      "✅ Categorical missing values filled with mode.\n"
     ]
    }
   ],
   "source": [
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "print(train.dtypes)\n",
    "categorical_features = train.select_dtypes(include=['object']).columns\n",
    "print(categorical_features)\n",
    "missing_in_test = [col for col in categorical_features if col not in test.columns]\n",
    "for col in missing_in_test:\n",
    "    test[col] = np.nan\n",
    "\n",
    "# train[categorical_features] = cat_imputer.fit_transform(train[categorical_features])\n",
    "# test[categorical_features] = cat_imputer.transform(test[categorical_features])\n",
    "\n",
    "print(\"✅ Categorical missing values filled with mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Missing Values in Train Dataset After Filling:\n",
      "Basic_Demos-Enroll_Season    0\n",
      "Stat_47                      0\n",
      "Stat_40                      0\n",
      "Stat_41                      0\n",
      "Stat_42                      0\n",
      "Stat_43                      0\n",
      "Stat_44                      0\n",
      "Stat_45                      0\n",
      "Stat_46                      0\n",
      "Stat_48                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔍 Missing Values in Train Dataset After Filling:\")\n",
    "print(train.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將類別型特徵進行編碼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 類別型特徵已進行 Label Encoding\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "for col in categorical_features:\n",
    "    if col == \"id\":\n",
    "        continue\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "\n",
    "print(\"✅ 類別型特徵已進行 Label Encoding\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將資料進行標準化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 數值特徵已進行標準化\n"
     ]
    }
   ],
   "source": [
    "numerical_features = [col for col in numerical_features if col not in ['sii', 'id']]\n",
    "scaler = StandardScaler()\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])\n",
    "test[numerical_features] = scaler.transform(test[numerical_features])\n",
    "\n",
    "print(\"✅ 數值特徵已進行標準化\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 異常值檢測\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in numerical_features:\n",
    "#     Q1 = train[col].quantile(0.25)\n",
    "#     Q3 = train[col].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     train = train[(train[col] >= lower_bound) & (train[col] <= upper_bound)]\n",
    "\n",
    "# print(\"✅ 異常值已使用 IQR 方法處理\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 儲存處理後的資料\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 處理後的資料已保存為 'cleaned_train.csv'\n"
     ]
    }
   ],
   "source": [
    "train.to_csv('cleaned_train.csv', index=False)\n",
    "\n",
    "print(\"✅ 處理後的資料已保存為 'cleaned_train.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 選擇的 20 個最佳特徵： Index(['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
      "       'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI', 'Physical-Height',\n",
      "       'Physical-Weight', 'Physical-Waist_Circumference',\n",
      "       'Physical-Diastolic_BP',\n",
      "       ...\n",
      "       'Stat_83', 'Stat_84', 'Stat_85', 'Stat_86', 'Stat_87', 'Stat_88',\n",
      "       'Stat_89', 'Stat_90', 'Stat_94', 'Stat_95'],\n",
      "      dtype='object', length=120)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# 1️⃣ 移除 `sii` 和 `id`\n",
    "X_train = train.drop(columns=['sii'])\n",
    "y_train = train['sii']\n",
    "X_test = test\n",
    "\n",
    "# 2️⃣ 確保 `train` 和 `test` 特徵名稱一致\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# 3️⃣ 特徵選擇\n",
    "selector = SelectKBest(score_func=f_regression, k=120)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# 獲取選擇的特徵名稱\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(\"✅ 選擇的 20 個最佳特徵：\", selected_features)\n",
    "\n",
    "# 4️⃣ 在 `test` 中應用相同的特徵選擇\n",
    "X_test_selected = X_test[selected_features].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 交叉驗證平均準確率： 0.6127673489458478\n",
      "✅ 模型評估報告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.81      0.67      1594\n",
      "         1.0       0.71      0.32      0.44      1594\n",
      "         2.0       0.67      0.48      0.56      1594\n",
      "         3.0       0.68      0.98      0.80      1594\n",
      "\n",
      "    accuracy                           0.65      6376\n",
      "   macro avg       0.66      0.65      0.62      6376\n",
      "weighted avg       0.66      0.65      0.62      6376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# 訓練分類模型\n",
    "X = train[selected_features]\n",
    "y = train['sii']\n",
    "\n",
    "# 應用 SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=300, random_state=42, max_depth=5, class_weight= 'balanced', min_samples_split=5, min_samples_leaf=4)\n",
    "\n",
    "# 交叉驗證\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"✅ 交叉驗證平均準確率：\", cv_scores.mean())\n",
    "\n",
    "# 模型訓練與預測\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(test[selected_features])\n",
    "\n",
    "# 評估模型效能\n",
    "print(\"✅ 模型評估報告：\")\n",
    "print(classification_report(y_train_resampled, model.predict(X_train_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'class_weight': ['balanced']\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     ExtraTreesClassifier(random_state=42),\n",
    "#     param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "# print(\"✅ 最佳參數：\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy')\n",
    "# search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# print(\"✅ 最佳參數:\", search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 預測結果已保存為 'final_submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# 儲存預測結果\n",
    "test_id = pd.read_csv(\"test.csv\")\n",
    "submission = pd.DataFrame({'id': test_id['id'], 'sii': y_pred})\n",
    "submission.to_csv('final_submission.csv', index=False)\n",
    "\n",
    "print(\"✅ 預測結果已保存為 'final_submission.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
