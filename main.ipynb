{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 996/996 [00:56<00:00, 17.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"Stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_ts = load_time_series(\"series_train.parquet\")\n",
    "test_ts = load_time_series(\"series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "5       1.0\n",
       "       ... \n",
       "3953    0.0\n",
       "3954    1.0\n",
       "3955    1.0\n",
       "3957    1.0\n",
       "3958    0.0\n",
       "Name: sii, Length: 2736, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', \n",
    "          'FGC-Season', 'BIA-Season', 'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('object')\n",
    "    return df\n",
    "        \n",
    "train = update(train)\n",
    "test = update(test)\n",
    "train['sii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['sii'] == 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2736 entries, 0 to 3958\n",
      "Columns: 155 entries, Basic_Demos-Enroll_Season to Stat_95\n",
      "dtypes: float64(143), int64(2), object(10)\n",
      "memory usage: 3.3+ MB\n",
      "None\n",
      "\n",
      "Test Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Columns: 154 entries, Basic_Demos-Enroll_Season to Stat_95\n",
      "dtypes: float64(142), int64(2), object(10)\n",
      "memory usage: 24.2+ KB\n",
      "None\n",
      "\n",
      "Missing Values in Train Dataset:\n",
      "PAQ_A-PAQ_A_Total               2373\n",
      "Physical-Waist_Circumference    2253\n",
      "Fitness_Endurance-Time_Sec      2008\n",
      "Fitness_Endurance-Time_Mins     2008\n",
      "Fitness_Endurance-Max_Stage     2005\n",
      "FGC-FGC_GSD_Zone                1872\n",
      "FGC-FGC_GSND_Zone               1872\n",
      "FGC-FGC_GSD                     1865\n",
      "FGC-FGC_GSND                    1864\n",
      "Stat_43                         1740\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Test Dataset:\n",
      "PAQ_A-PAQ_A_Total    19\n",
      "Stat_19              18\n",
      "Stat_47              18\n",
      "Stat_41              18\n",
      "Stat_42              18\n",
      "Stat_43              18\n",
      "Stat_44              18\n",
      "Stat_45              18\n",
      "Stat_46              18\n",
      "Stat_48              18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# æª¢è¦– train å’Œ test è³‡æ–™çš„åŸºæœ¬è³‡è¨Š\n",
    "print(\"Train Dataset Info:\")\n",
    "print(train.info())\n",
    "print(\"\\nTest Dataset Info:\")\n",
    "print(test.info())\n",
    "\n",
    "# é¡¯ç¤ºç¼ºå¤±å€¼åˆ†å¸ƒ\n",
    "print(\"\\nMissing Values in Train Dataset:\")\n",
    "print(train.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\nMissing Values in Test Dataset:\")\n",
    "print(test.isnull().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¼ºå¤±å€¼è™•ç†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é‡å°é€£çºŒåž‹çš„è³‡æ–™ç‰¹å¾µ âž¡ï¸ ä½¿ç”¨ä¸­ä½æ•¸å¡«è£œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Continuous numerical missing values filled with median.\n"
     ]
    }
   ],
   "source": [
    "num_imputer = SimpleImputer(strategy='median')\n",
    "numerical_features = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "missing_in_test = [col for col in numerical_features if col not in test.columns]\n",
    "for col in missing_in_test:\n",
    "    test[col] = np.nan\n",
    "\n",
    "train[numerical_features] = num_imputer.fit_transform(train[numerical_features])\n",
    "test[numerical_features] = num_imputer.transform(test[numerical_features])\n",
    "print(\"âœ… Continuous numerical missing values filled with median.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é‡å°é¡žåˆ¥åž‹çš„è³‡æ–™ç‰¹å¾µ âž¡ï¸ ä½¿ç”¨å¤šæ•¸å¡«è£œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic_Demos-Enroll_Season     object\n",
      "Basic_Demos-Age              float64\n",
      "Basic_Demos-Sex              float64\n",
      "CGAS-Season                   object\n",
      "CGAS-CGAS_Score              float64\n",
      "                              ...   \n",
      "Stat_91                      float64\n",
      "Stat_92                      float64\n",
      "Stat_93                      float64\n",
      "Stat_94                      float64\n",
      "Stat_95                      float64\n",
      "Length: 155, dtype: object\n",
      "Index(['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season',\n",
      "       'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', 'PAQ_A-Season',\n",
      "       'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season'],\n",
      "      dtype='object')\n",
      "âœ… Categorical missing values filled with mode.\n"
     ]
    }
   ],
   "source": [
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "print(train.dtypes)\n",
    "categorical_features = train.select_dtypes(include=['object']).columns\n",
    "print(categorical_features)\n",
    "missing_in_test = [col for col in categorical_features if col not in test.columns]\n",
    "for col in missing_in_test:\n",
    "    test[col] = np.nan\n",
    "\n",
    "# train[categorical_features] = cat_imputer.fit_transform(train[categorical_features])\n",
    "# test[categorical_features] = cat_imputer.transform(test[categorical_features])\n",
    "\n",
    "print(\"âœ… Categorical missing values filled with mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Missing Values in Train Dataset After Filling:\n",
      "Basic_Demos-Enroll_Season    0\n",
      "Stat_47                      0\n",
      "Stat_40                      0\n",
      "Stat_41                      0\n",
      "Stat_42                      0\n",
      "Stat_43                      0\n",
      "Stat_44                      0\n",
      "Stat_45                      0\n",
      "Stat_46                      0\n",
      "Stat_48                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ” Missing Values in Train Dataset After Filling:\")\n",
    "print(train.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å°‡é¡žåˆ¥åž‹ç‰¹å¾µé€²è¡Œç·¨ç¢¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é¡žåˆ¥åž‹ç‰¹å¾µå·²é€²è¡Œ Label Encoding\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "for col in categorical_features:\n",
    "    if col == \"id\":\n",
    "        continue\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "\n",
    "print(\"âœ… é¡žåˆ¥åž‹ç‰¹å¾µå·²é€²è¡Œ Label Encoding\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å°‡è³‡æ–™é€²è¡Œæ¨™æº–åŒ–\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•¸å€¼ç‰¹å¾µå·²é€²è¡Œæ¨™æº–åŒ–\n"
     ]
    }
   ],
   "source": [
    "numerical_features = [col for col in numerical_features if col not in ['sii', 'id']]\n",
    "scaler = StandardScaler()\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])\n",
    "test[numerical_features] = scaler.transform(test[numerical_features])\n",
    "\n",
    "print(\"âœ… æ•¸å€¼ç‰¹å¾µå·²é€²è¡Œæ¨™æº–åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç•°å¸¸å€¼æª¢æ¸¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in numerical_features:\n",
    "#     Q1 = train[col].quantile(0.25)\n",
    "#     Q3 = train[col].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     train = train[(train[col] >= lower_bound) & (train[col] <= upper_bound)]\n",
    "\n",
    "# print(\"âœ… ç•°å¸¸å€¼å·²ä½¿ç”¨ IQR æ–¹æ³•è™•ç†\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å„²å­˜è™•ç†å¾Œçš„è³‡æ–™\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è™•ç†å¾Œçš„è³‡æ–™å·²ä¿å­˜ç‚º 'cleaned_train.csv'\n"
     ]
    }
   ],
   "source": [
    "train.to_csv('cleaned_train.csv', index=False)\n",
    "\n",
    "print(\"âœ… è™•ç†å¾Œçš„è³‡æ–™å·²ä¿å­˜ç‚º 'cleaned_train.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é¸æ“‡çš„ 20 å€‹æœ€ä½³ç‰¹å¾µï¼š Index(['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
      "       'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI', 'Physical-Height',\n",
      "       'Physical-Weight', 'Physical-Waist_Circumference',\n",
      "       'Physical-Diastolic_BP',\n",
      "       ...\n",
      "       'Stat_83', 'Stat_84', 'Stat_85', 'Stat_86', 'Stat_87', 'Stat_88',\n",
      "       'Stat_89', 'Stat_90', 'Stat_94', 'Stat_95'],\n",
      "      dtype='object', length=120)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# 1ï¸âƒ£ ç§»é™¤ `sii` å’Œ `id`\n",
    "X_train = train.drop(columns=['sii'])\n",
    "y_train = train['sii']\n",
    "X_test = test\n",
    "\n",
    "# 2ï¸âƒ£ ç¢ºä¿ `train` å’Œ `test` ç‰¹å¾µåç¨±ä¸€è‡´\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# 3ï¸âƒ£ ç‰¹å¾µé¸æ“‡\n",
    "selector = SelectKBest(score_func=f_regression, k=120)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# ç²å–é¸æ“‡çš„ç‰¹å¾µåç¨±\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(\"âœ… é¸æ“‡çš„ 20 å€‹æœ€ä½³ç‰¹å¾µï¼š\", selected_features)\n",
    "\n",
    "# 4ï¸âƒ£ åœ¨ `test` ä¸­æ‡‰ç”¨ç›¸åŒçš„ç‰¹å¾µé¸æ“‡\n",
    "X_test_selected = X_test[selected_features].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… äº¤å‰é©—è­‰å¹³å‡æº–ç¢ºçŽ‡ï¼š 0.6127673489458478\n",
      "âœ… æ¨¡åž‹è©•ä¼°å ±å‘Šï¼š\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.81      0.67      1594\n",
      "         1.0       0.71      0.32      0.44      1594\n",
      "         2.0       0.67      0.48      0.56      1594\n",
      "         3.0       0.68      0.98      0.80      1594\n",
      "\n",
      "    accuracy                           0.65      6376\n",
      "   macro avg       0.66      0.65      0.62      6376\n",
      "weighted avg       0.66      0.65      0.62      6376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# è¨“ç·´åˆ†é¡žæ¨¡åž‹\n",
    "X = train[selected_features]\n",
    "y = train['sii']\n",
    "\n",
    "# æ‡‰ç”¨ SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=300, random_state=42, max_depth=5, class_weight= 'balanced', min_samples_split=5, min_samples_leaf=4)\n",
    "\n",
    "# äº¤å‰é©—è­‰\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"âœ… äº¤å‰é©—è­‰å¹³å‡æº–ç¢ºçŽ‡ï¼š\", cv_scores.mean())\n",
    "\n",
    "# æ¨¡åž‹è¨“ç·´èˆ‡é æ¸¬\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(test[selected_features])\n",
    "\n",
    "# è©•ä¼°æ¨¡åž‹æ•ˆèƒ½\n",
    "print(\"âœ… æ¨¡åž‹è©•ä¼°å ±å‘Šï¼š\")\n",
    "print(classification_report(y_train_resampled, model.predict(X_train_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'class_weight': ['balanced']\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     ExtraTreesClassifier(random_state=42),\n",
    "#     param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "# print(\"âœ… æœ€ä½³åƒæ•¸ï¼š\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy')\n",
    "# search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# print(\"âœ… æœ€ä½³åƒæ•¸:\", search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é æ¸¬çµæžœå·²ä¿å­˜ç‚º 'final_submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# å„²å­˜é æ¸¬çµæžœ\n",
    "test_id = pd.read_csv(\"test.csv\")\n",
    "submission = pd.DataFrame({'id': test_id['id'], 'sii': y_pred})\n",
    "submission.to_csv('final_submission.csv', index=False)\n",
    "\n",
    "print(\"âœ… é æ¸¬çµæžœå·²ä¿å­˜ç‚º 'final_submission.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
